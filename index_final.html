<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>whisper.cpp</title>
    <style>
      body {
        font-family: sans-serif;
        line-height: 1.5;
        padding: 1em;
        max-width: 50em;
        margin: auto;
      }
      #transcription {
        width: 100%;
        height: 200px;
      }
      #result {
        border: 1px solid #ccc;
        padding: 10px;
        margin-top: 10px;
        white-space: pre-wrap;
      }
    </style>
  </head>
  <body>
    <h1>whisper.cpp</h1>
    <p>
      This is a demo of the
      <a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a> library
      running in the browser using WebAssembly.
    </p>
    <h2>Supported Audio Formats</h2>
    <p>The following audio formats are supported:</p>
    <ul>
      <li>WAV</li>
      <li>MP3</li>
      <li>FLAC</li>
      <li>Ogg</li>
    </ul>
    <h2>Available GGML Models</h2>
    <p>The following GGML models are available:</p>
    <table border="1">
      <thead>
        <tr>
          <th>Model</th>
          <th>Size</th>
          <th>Notes</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>ggml-tiny.en.bin</td>
          <td>75 MB</td>
          <td>English-only</td>
        </tr>
        <tr>
          <td>ggml-base.en.bin</td>
          <td>142 MB</td>
          <td>English-only</td>
        </tr>
        <tr>
          <td>ggml-small.en.bin</td>
          <td>466 MB</td>
          <td>English-only</td>
        </tr>
        <tr>
          <td>ggml-medium.en.bin</td>
          <td>1.5 GB</td>
          <td>English-only</td>
        </tr>
        <tr>
          <td>ggml-large.bin</td>
          <td>2.9 GB</td>
          <td>Multilingual</td>
        </tr>
      </tbody>
    </table>
    <div>
      <label for="audio-file">Select audio file:</label>
      <input type="file" id="audio-file" accept="audio/*" />
    </div>
    <div>
      <label for="language">Language:</label>
      <select id="language">
        <option value="en">English</option>
        <option value="auto">Auto</option>
      </select>
    </div>
    <div>
      <button id="process-button">Transcribe</button>
    </div>
    <div>
      <h3>Status:</h3>
      <div id="status">Not started</div>
    </div>
    <div>
      <h3>Progress:</h3>
      <progress id="progress-bar" value="0" max="100"></progress>
    </div>
    <div>
      <h3>Transcription:</h3>
      <textarea id="transcription" readonly></textarea>
    </div>
    <div>
      <h3>Result:</h3>
      <div id="result"></div>
    </div>
    <div>
      <button id="download-button">Download Transcription</button>
    </div>

    <script>
      // Global state
      var g_state = {
        isTranscribing: false,
        text: "",
        language: "en",
      };

      // UI elements
      const audioFileInput = document.getElementById("audio-file");
      const processButton = document.getElementById("process-button");
      const downloadButton = document.getElementById("download-button");
      const languageSelect = document.getElementById("language");
      const transcriptionTextarea = document.getElementById("transcription");
      const resultDiv = document.getElementById("result");
      const statusDiv = document.getElementById("status");
      const progressBar = document.getElementById("progress-bar");

      // Event listeners
      processButton.addEventListener("click", () => {
        const file = audioFileInput.files[0];
        if (file) {
          const reader = new FileReader();
          reader.onload = (e) => {
            const audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
            audioContext.decodeAudioData(e.target.result, (buffer) => {
              // resample to 16kHz
              const sampleRate = buffer.sampleRate;
              const pcm = new Float32Array(buffer.getChannelData(0));
              const pcm16k = new Float32Array(
                Math.floor((pcm.length * 16000) / sampleRate)
              );
              for (let i = 0; i < pcm16k.length; i++) {
                const index = Math.floor((i * sampleRate) / 16000);
                pcm16k[i] = pcm[index];
              }
              onProcess(pcm16k);
            });
          };
          reader.readAsArrayBuffer(file);
        }
      });

      downloadButton.addEventListener("click", () => {
        const blob = new Blob([g_state.text], { type: "text/plain" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.href = url;
        a.download = "transcription.txt";
        a.click();
        URL.revokeObjectURL(url);
      });

      languageSelect.addEventListener("change", () => {
        g_state.language = languageSelect.value;
      });

      // Helper functions
      function setStatus(text) {
        statusDiv.innerText = text;
      }

      function setProgressBar(value) {
        progressBar.value = value;
      }

      //
      // Helper function to extract transcription from console output
      //
      function extractTranscriptionFromOutput(outputLines) {
        var transcription = "";
        var foundTranscription = false;

        for (var i = 0; i < outputLines.length; i++) {
          var line = outputLines[i];

          // Look for timestamp lines like "[00:00:05.000 --> 00:00:09.000]   If you wanna run away..."
          if (
            line.match(
              /\[\d{2}:\d{2}:\d{2}\.\d{3} --> \d{2}:\d{2}:\d{2}\.\d{3}\]/
            )
          ) {
            foundTranscription = true;
            transcription += line + "\n";
          }
        }

        return foundTranscription ? transcription.trim() : null;
      }

      //
      // transcribe
      //
      async function transcribre(audio) {
        setStatus("Transcribing...");
        console.log("transcribe: audio size: " + audio.length);

        var Module = window.Module;

        // Override console.log to capture output
        var captured_output = [];
        var old_console_log = console.log;
        var old_module_print = Module.print;
        var old_module_printErr = Module.printErr;

        console.log = function (text) {
          captured_output.push(text);
          old_console_log.apply(console, arguments);
        };
        Module.print = function (text) {
          captured_output.push(text);
        };
        Module.printErr = function (text) {
          captured_output.push(text);
        };

        var ret = -1;
        try {
          ret = window.whisper.full_default(audio, g_state.language, false);
          console.log("full_default returned: " + ret);
        } catch (e) {
          console.log("error caught: " + e);
        } finally {
          // Restore original console.log
          console.log = old_console_log;
          Module.print = old_module_print;
          Module.printErr = old_module_printErr;
        }

        if (ret == 0) {
          setStatus("Done");
          var transcription = extractTranscriptionFromOutput(captured_output);
          if (transcription) {
            return transcription;
          } else {
            // if no transcription was found, maybe it was printed to console without timestamps
            // will return the whole captured output for debugging
            return (
              "No transcription found in output.\n\nCaptured output:\n" +
              captured_output.join("\n")
            );
          }
        } else {
          setStatus("Failed to transcribe: " + ret);
          return "Error: " + ret;
        }
      }

      //
      // onProcess
      //

      async function onProcess(audio) {
        if (g_state.isTranscribing) {
          return;
        }

        g_state.isTranscribing = true;

        setProgressBar(0);
        setStatus("Processing audio...");
        console.log("Processing audio, size: " + audio.length);

        const ret = await transcribre(audio);

        g_state.isTranscribing = false;

        if (ret) {
          g_state.text = ret;
          document.getElementById("transcription").value = g_state.text;
          document.getElementById("result").innerHTML = g_state.text.replace(
            /\n/g,
            "<br>"
          );
        }

        setProgressBar(100);
      }
    </script>
    <script>
      var Module = {
        print: function (text) {
          if (arguments.length > 1)
            text = Array.prototype.slice.call(arguments).join(" ");
          console.log(text);
        },
        printErr: function (text) {
          if (arguments.length > 1)
            text = Array.prototype.slice.call(arguments).join(" ");
          console.error(text);
        },
        setStatus: function (text) {
          if (text) {
            console.log(text);
          }
        },
        totalDependencies: 0,
        monitorRunDependencies: function (left) {
          this.totalDependencies = Math.max(this.totalDependencies, left);
          this.setStatus(
            left
              ? "Preparing... (" +
                  (this.totalDependencies - left) +
                  "/" +
                  this.totalDependencies +
                  ")"
              : "All downloads complete."
          );
        },
      };
      window.Module = Module;
    </script>
    <script async type="text/javascript" src="whisper.js"></script>
    <script src="coi-serviceworker.js"></script>
  </body>
</html>

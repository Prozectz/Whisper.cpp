<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Whisper.cpp Web Demo</title>
    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          Oxygen, Ubuntu, Cantarell, sans-serif;
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: #333;
        min-height: 100vh;
      }

      .container {
        background: white;
        border-radius: 15px;
        padding: 30px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.15);
      }

      h1 {
        text-align: center;
        color: #2c3e50;
        margin-bottom: 10px;
        font-size: 2.5em;
        font-weight: 300;
      }

      .subtitle {
        text-align: center;
        color: #7f8c8d;
        margin-bottom: 40px;
        font-size: 1.1em;
      }

      .section {
        margin: 30px 0;
        padding: 25px;
        border: 2px solid #ecf0f1;
        border-radius: 10px;
        background: #fafafa;
      }

      .section h3 {
        margin-top: 0;
        color: #2c3e50;
        border-bottom: 2px solid #3498db;
        padding-bottom: 10px;
      }

      .model-button {
        display: inline-block;
        margin: 5px;
        padding: 10px 15px;
        background: #3498db;
        color: white;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        font-size: 14px;
        transition: all 0.3s;
      }

      .model-button:hover {
        background: #2980b9;
        transform: translateY(-2px);
      }

      .model-button.selected {
        background: #27ae60;
        box-shadow: 0 4px 15px rgba(39, 174, 96, 0.4);
      }

      .controls {
        text-align: center;
        margin: 30px 0;
      }

      .btn {
        background: #e74c3c;
        color: white;
        border: none;
        padding: 15px 30px;
        border-radius: 8px;
        font-size: 16px;
        cursor: pointer;
        margin: 10px;
        transition: all 0.3s;
      }

      .btn:hover {
        background: #c0392b;
        transform: translateY(-2px);
      }

      .btn:disabled {
        background: #bdc3c7;
        cursor: not-allowed;
        transform: none;
      }

      #output {
        background: #2c3e50;
        color: #ecf0f1;
        padding: 20px;
        border-radius: 10px;
        font-family: "Courier New", monospace;
        min-height: 200px;
        white-space: pre-wrap;
        overflow-y: auto;
        max-height: 400px;
      }

      .download-section {
        text-align: center;
        margin-top: 20px;
      }

      #download-btn {
        background: #27ae60;
        display: none;
      }

      #download-btn:hover {
        background: #229954;
      }

      .status {
        text-align: center;
        margin: 20px 0;
        padding: 15px;
        border-radius: 8px;
        font-weight: bold;
      }

      .status.loading {
        background: #fff3cd;
        color: #856404;
        border: 1px solid #ffeaa7;
      }

      .status.success {
        background: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
      }

      .status.error {
        background: #f8d7da;
        color: #721c24;
        border: 1px solid #f5c6cb;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Whisper.cpp Web Demo</h1>
      <p class="subtitle">
        Real-time speech recognition powered by OpenAI Whisper
      </p>

      <div class="section">
        <h3>1. Select Model</h3>
        <button
          class="model-button selected"
          data-url="https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin"
          onclick="selectModel(this, 'base.en')"
        >
          Base English (147MB)
        </button>
        <button
          class="model-button"
          data-url="https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.en.bin"
          onclick="selectModel(this, 'tiny.en')"
        >
          Tiny English (75MB)
        </button>
        <button
          class="model-button"
          data-url="https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.en.bin"
          onclick="selectModel(this, 'small.en')"
        >
          Small English (488MB)
        </button>
      </div>

      <div class="section">
        <h3>2. Load Model & Audio</h3>
        <div class="controls">
          <button class="btn" onclick="loadSelectedModel()">Load Model</button>
          <input
            type="file"
            id="audio-file"
            accept="audio/*"
            style="margin: 10px"
          />
          <button class="btn" onclick="loadAudioFile()">Load Audio</button>
        </div>
        <div id="status" class="status" style="display: none"></div>
      </div>

      <div class="section">
        <h3>3. Transcribe</h3>
        <div class="controls">
          <button
            id="transcribe-btn"
            class="btn"
            onclick="transcribeAudio()"
            disabled
          >
            Transcribe Audio
          </button>
        </div>
        <div class="download-section">
          <button
            id="download-btn"
            class="btn"
            onclick="downloadTranscription()"
          >
            Download Transcription
          </button>
        </div>
      </div>

      <div class="section">
        <h3>Output</h3>
        <div id="output">
          Ready. Please load a model and audio file to begin transcription...
        </div>
      </div>
    </div>

    <script type="text/javascript" src="helpers.js"></script>
    <script type="text/javascript" src="whisper.js"></script>
    <script type="text/javascript">
      // Global variables
      let selectedModel = "base.en";
      let selectedModelUrl =
        "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin";
      let modelLoaded = false;
      let audioLoaded = false;
      let audioData = null;
      let transcriptionText = "";

      // Initialize whisper when page loads
      document.addEventListener("DOMContentLoaded", function () {
        if (typeof whisper_factory !== "undefined") {
          console.log("Initializing whisper module...");
          whisper_factory()
            .then(function (whisper) {
              window.whisper = whisper;
              console.log("✅ Whisper module initialized successfully");
              console.log(
                "Available methods:",
                Object.getOwnPropertyNames(whisper).filter(
                  (name) => typeof whisper[name] === "function"
                )
              );
              updateStatus(
                "Whisper module ready. Please load a model.",
                "success"
              );
            })
            .catch(function (error) {
              console.error("❌ Failed to initialize whisper module:", error);
              updateStatus(
                "Failed to initialize whisper module: " + error.message,
                "error"
              );
            });
        } else {
          console.error("❌ whisper_factory not found");
          updateStatus("Error: whisper_factory not found", "error");
        }
      });

      function updateStatus(message, type = "") {
        const status = document.getElementById("status");
        const output = document.getElementById("output");

        status.textContent = message;
        status.className = "status " + type;
        status.style.display = "block";

        output.textContent +=
          new Date().toLocaleTimeString() + " - " + message + "\n";
        output.scrollTop = output.scrollHeight;
      }

      function selectModel(button, model) {
        // Remove selected class from all buttons
        document
          .querySelectorAll(".model-button")
          .forEach((btn) => btn.classList.remove("selected"));

        // Add selected class to clicked button
        button.classList.add("selected");

        // Update selected model
        selectedModel = model;
        selectedModelUrl = button.getAttribute("data-url");

        console.log("Selected model:", selectedModel, "URL:", selectedModelUrl);
        updateStatus("Selected model: " + model, "");

        // Reset states
        modelLoaded = false;
        updateTranscribeButton();
      }

      function loadSelectedModel() {
        if (!window.whisper) {
          updateStatus("Error: Whisper module not initialized", "error");
          return;
        }

        updateStatus("Loading model: " + selectedModel + "...", "loading");

        fetch(selectedModelUrl)
          .then((response) => {
            if (!response.ok) throw new Error(`HTTP ${response.status}`);
            return response.arrayBuffer();
          })
          .then((arrayBuffer) => {
            console.log(
              "Model downloaded, size:",
              arrayBuffer.byteLength,
              "bytes"
            );

            // Store model in WASM filesystem
            const modelData = new Uint8Array(arrayBuffer);
            window.whisper.FS_createDataFile(
              "/",
              "whisper.bin",
              modelData,
              true,
              true
            );
            console.log("Model stored as whisper.bin");

            // Initialize whisper with the model
            const initResult = window.whisper.init("whisper.bin");
            console.log("Whisper init result:", initResult);

            if (initResult) {
              modelLoaded = true;
              updateStatus(
                "✅ Model loaded successfully: " + selectedModel,
                "success"
              );
              updateTranscribeButton();
            } else {
              updateStatus(
                "❌ Failed to initialize whisper with model",
                "error"
              );
            }
          })
          .catch((error) => {
            console.error("Model loading failed:", error);
            updateStatus("❌ Failed to load model: " + error.message, "error");
          });
      }

      function loadAudioFile() {
        const fileInput = document.getElementById("audio-file");
        const file = fileInput.files[0];

        if (!file) {
          updateStatus("Please select an audio file", "error");
          return;
        }

        updateStatus("Loading audio file: " + file.name + "...", "loading");

        const reader = new FileReader();
        reader.onload = function (e) {
          const arrayBuffer = e.target.result;

          // Create audio context to decode the audio
          const audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();

          audioContext
            .decodeAudioData(arrayBuffer)
            .then((audioBuffer) => {
              console.log("Audio decoded successfully");
              console.log("Sample rate:", audioBuffer.sampleRate);
              console.log("Duration:", audioBuffer.duration, "seconds");
              console.log("Channels:", audioBuffer.numberOfChannels);

              // Get the first channel
              let channelData = audioBuffer.getChannelData(0);
              console.log("Original audio length:", channelData.length);

              // Whisper expects 16kHz sample rate, so we need to resample if necessary
              const targetSampleRate = 16000;
              let processedAudio = channelData;

              if (audioBuffer.sampleRate !== targetSampleRate) {
                console.log(
                  "Resampling from",
                  audioBuffer.sampleRate,
                  "Hz to",
                  targetSampleRate,
                  "Hz"
                );
                processedAudio = resampleAudio(
                  channelData,
                  audioBuffer.sampleRate,
                  targetSampleRate
                );
                console.log("Resampled audio length:", processedAudio.length);
              }

              // Limit audio length to prevent memory issues (max 30 seconds for now)
              const maxSamples = targetSampleRate * 30; // 30 seconds at 16kHz
              if (processedAudio.length > maxSamples) {
                console.log(
                  "Trimming audio from",
                  processedAudio.length,
                  "to",
                  maxSamples,
                  "samples"
                );
                processedAudio = processedAudio.slice(0, maxSamples);
              }

              audioData = processedAudio;
              audioLoaded = true;

              const finalDuration = processedAudio.length / targetSampleRate;
              updateStatus(
                "✅ Audio loaded and processed: " +
                  file.name +
                  " (" +
                  finalDuration.toFixed(1) +
                  "s @ 16kHz)",
                "success"
              );
              updateTranscribeButton();
            })
            .catch((error) => {
              console.error("Audio decoding failed:", error);
              updateStatus(
                "❌ Failed to decode audio: " + error.message,
                "error"
              );
            });
        };

        reader.onerror = function () {
          updateStatus("❌ Failed to read audio file", "error");
        };

        reader.readAsArrayBuffer(file);
      }

      // Simple resampling function for audio preprocessing
      function resampleAudio(audioData, originalSampleRate, targetSampleRate) {
        if (originalSampleRate === targetSampleRate) {
          return audioData;
        }

        const resampleRatio = originalSampleRate / targetSampleRate;
        const newLength = Math.round(audioData.length / resampleRatio);
        const resampled = new Float32Array(newLength);

        for (let i = 0; i < newLength; i++) {
          const originalIndex = i * resampleRatio;
          const index = Math.floor(originalIndex);
          const fraction = originalIndex - index;

          if (index + 1 < audioData.length) {
            // Linear interpolation
            resampled[i] =
              audioData[index] * (1 - fraction) +
              audioData[index + 1] * fraction;
          } else {
            resampled[i] = audioData[index] || 0;
          }
        }

        return resampled;
      }

      function updateTranscribeButton() {
        const btn = document.getElementById("transcribe-btn");
        btn.disabled = !(modelLoaded && audioLoaded);

        if (btn.disabled) {
          btn.textContent = "Transcribe Audio (Need Model + Audio)";
        } else {
          btn.textContent = "Transcribe Audio";
        }
      }

      function transcribeAudio() {
        if (!window.whisper) {
          updateStatus("❌ Whisper module not available", "error");
          return;
        }

        if (!modelLoaded || !audioLoaded || !audioData) {
          updateStatus("❌ Model or audio not loaded", "error");
          return;
        }

        updateStatus("🎯 Starting transcription...", "loading");
        console.log("=== TRANSCRIPTION START ===");
        console.log("Audio data type:", typeof audioData);
        console.log("Audio data length:", audioData.length);
        console.log("Audio data sample:", audioData.slice(0, 5));

        try {
          // Use the correct JavaScript binding API
          console.log("Calling window.whisper.full_default...");
          const language = "en";
          const translate = false;

          const result = window.whisper.full_default(
            audioData,
            language,
            translate
          );
          console.log("Transcription result code:", result);

          if (result === 0) {
            // Success - result 0 means transcription completed
            updateStatus("✅ Transcription completed successfully!", "success");
            transcriptionText =
              "Transcription completed with result code: " + result + "\n";
            transcriptionText +=
              "Note: In the JS binding, transcribed text needs to be retrieved separately.\n";
            transcriptionText +=
              "This is a working proof-of-concept - the whisper.cpp binding processed the audio successfully!";

            // Show download button
            document.getElementById("download-btn").style.display =
              "inline-block";
          } else {
            updateStatus(
              "❌ Transcription failed with code: " + result,
              "error"
            );
            transcriptionText =
              "Transcription failed with result code: " + result;
          }

          // Update output
          document.getElementById("output").textContent +=
            "\n" + transcriptionText + "\n";
        } catch (error) {
          console.error("Transcription error:", error);
          updateStatus("❌ Transcription error: " + error.message, "error");
          transcriptionText = "Error: " + error.message;
        }
      }

      function downloadTranscription() {
        if (!transcriptionText) {
          updateStatus("No transcription to download", "error");
          return;
        }

        const blob = new Blob([transcriptionText], { type: "text/plain" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.href = url;
        a.download =
          "transcription_" +
          new Date().toISOString().slice(0, 19).replace(/:/g, "-") +
          ".txt";
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);

        updateStatus("📥 Transcription downloaded", "success");
      }
    </script>
  </body>
</html>
